{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad770e5",
   "metadata": {},
   "source": [
    "# Katastrophenrettung - Simulation und Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166fee5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from schema import *\n",
    "from typing import List, Dict\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d39c52",
   "metadata": {},
   "source": [
    "## Initialisierung der Simulation [Aufgaben 1, 3, 5]\n",
    "\n",
    "Als Algorithmus für die Generierung des Labyrinths haben wir den **iterativen Ansatz des random DFS** gewählt, da die Struktur des erzeugten Labyrinths für die Simulation passend war.\n",
    "\n",
    "Die Ausgänge des Labyrinths (**EXIT**) werden zufällig an den Rändern platziert. Sie dienen als Sicherheitszone, der sog. Savezone, an welchen die Überlebenden versorgt werden können.\n",
    "Anschließend werden die Überlebenden (**SURV**) zufällig im Labyrinth platziert, wobei sie nicht an den Positionen der Savezones platziert werden dürfen.\n",
    "\n",
    "Der Roboterhund (**AGENT**) wird an eine der Savezones per Zufall platziert, von wo aus er startet. Wir haben uns dagegen entschieden, den Roboterhund an einer zufälligen Position, unabhängig von den Savezones, im Labyrinth zu platzieren.\n",
    "Das Ziel der Simulation ist es, alle Überlebenden in möglichst wenig benötigten Schritten und bewegten Feldern durch den Roboterhund in die Sicherheitszonen zu bringen, sodass sie versorgt werden können.\n",
    "\n",
    "_Bitte beachten: In dieser Darstellung bedeuten die Kanten, dass zwischen zwei Punkten eine Verbindung existiert._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters:\n",
    "# Width and height of the environment\n",
    "# Number of survivors, save zones and robots (agents)\n",
    "environment = EnvironmentModel(\n",
    "    width=10,\n",
    "    height=10,\n",
    "    n_survivors=5,\n",
    "    n_save_zones=4, # must be >1 for task 4\n",
    "    n_robot_agents=1, # must be 1 for task 4\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# unchanged environment for later runs (task 4) needed\n",
    "initial_environment = deepcopy(environment)\n",
    "\n",
    "# Printing object locations\n",
    "for s in environment.survivors:\n",
    "    print(f\"Survivor bei ({s.tile.x}, {s.tile.y})\")\n",
    "print()\n",
    "for sz in environment.save_zones:\n",
    "    print(f\"Savezone bei ({sz.tile.x}, {sz.tile.y})\")\n",
    "print()\n",
    "for ra in environment.agents_by_type[RobotAgent]:\n",
    "    print(f\"Agent bei ({ra.tile.x}, {ra.tile.y})\")\n",
    "    \n",
    "# Visualizing as a networkX graph\n",
    "environment.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c0ba1",
   "metadata": {},
   "source": [
    "## Metriken [Aufgabe 2]\n",
    "### Pfadlänge\n",
    "Als Pfadlänge wurde der Abstand zwischen den Savezones und den Überlebenden gewählt, da die Pfadlänge auf alle Punkte für das Lösen des Problems nicht von Bedeutung wäre.\n",
    "Würde man die Pfadlänge zwischen allen Positionen im Labyrinth betrachten, so wäre die minimale Pfadlänge 1, sobald zwei Positionen eine direkte Verbindung haben - bei einem Labyrinth also jederzeit.  \n",
    "\n",
    "Mittels **A-Star** wird die Pfadlänge zwischen jeder Savezone zu jedem Überlebenden ermittelt. Anschließend werden die minimalen, maximalen und durchschnittlichen Werte ermittelt.\n",
    "\n",
    "_Die Berechnung der Pfadlängen für jedes Kästchen statt zwischen den Savezones und den Überlebenden wäre mit unserem Datenmodell sogar einfacher, wir sehen darin jedoch keinen Mehrwert._\n",
    "\n",
    "_Bei 4 Savezones und 5 Überlebenden werden somit 4*5=20 Pfadlängen generiert._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlengths: List[int] = environment.get_pathlengths_savezones_to_survivors()\n",
    "min_pathlength: int = min(pathlengths)\n",
    "max_pathlength: int = max(pathlengths)\n",
    "mean_pathlength: float = sum(pathlengths) / len(pathlengths)\n",
    "\n",
    "print(\"Die minimale Pfadlänge beträgt:\", min_pathlength)\n",
    "print(\"Die maximale Pfadlänge beträgt:\", max_pathlength)\n",
    "print(\"Die durchschnittliche Pfadlänge beträgt:\", mean_pathlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e558d2",
   "metadata": {},
   "source": [
    "### Dichte von Wänden\n",
    "\n",
    "Zur Berechnung der Wände wurde mit einem Graphen gearbeitet.\n",
    "\n",
    "Die Dichte ergibt sich aus der Anzahl der Kanten zwischen den Positionen des Labyrinths _durch_ die insgesamt möglichen Kanten zwischen den jeweiligen Positionen des Labyrinths.\n",
    "\n",
    "_Beispiel:_\n",
    "_Anzahl der Kanten: 20;_\n",
    "_Anzahl möglicher Kanten bei einem 5x5 Maze: 40._\n",
    "\n",
    "_Dichte: 20 / 40 = 0.50._\n",
    "\n",
    "Die Dichte sagt somit aus, wie viel Prozent der möglichen Knoten zwischen den Positionen wirklich ausgeprägt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_wall_density: float = environment.get_mean_wall_density()\n",
    "print(\"Die durchschnittliche Wanddichte beträgt:\", mean_wall_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cfa35",
   "metadata": {},
   "source": [
    "### Anzahl der Ausgänge\n",
    "\n",
    "Durch unsere Datenstruktur lässt sich die Anzahl der Ausgänge einfach bestimmen.\n",
    "\n",
    "Ausgänge aus dem Labyrinth existieren nur an den Stellen, wo die Savezones sind.\n",
    "Wenn ein Überlebender an eine Savezone gelangt, wird er auch automatisch als _gerettet_ markiert und ist nicht mehr für die Simulation relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2261916",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_count: int = environment.get_exit_count()\n",
    "print(\"Die Anzahl der Ausgänge beträgt:\", exit_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3582bd",
   "metadata": {},
   "source": [
    "### Symmetrien\n",
    "\n",
    "Symmetrien fest als vorhanden oder nicht vorhanden zu klassifizieren ist in der Betrachtung eines Labyrinths nicht zielführend, da die Wahrscheinlichkeit für das Auftreten einer reinen Symmetrie bei Labyrinthen mit annehmbarer Größe (z.B. 10x10) zu klein wäre.\n",
    "\n",
    "Stattdessen berechnen wir den **Grad der vertikalen und horizontalen Symmetrie in Prozent**.\n",
    "\n",
    "Beispiel: Die horizontale Symmetrie wird ermittelt, indem man das Labyrinth vertikal in der Mitte _durchschneidet_. (Offensichtlich gilt bei Labyrinthen mit ungerader Breite, dass die mittlere Spalte ignoriert werden kann.)\n",
    "Nun wird für jedes gegenüberliegende Kästchenpärchen verglichen, wie viele Wände spiegelverkehrt übereinstimmen.\n",
    "Bei einer 25-prozentigen horizontalen Symmetrie stimmen somit 1/4 der Wände überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "north_south_symmetry, east_west_symmetry = environment.calculate_axial_symmetry()\n",
    "\n",
    "print(f\"Der Grad der Nord-Süd-Symmetrie beträgt: {round(north_south_symmetry * 100, 2)}%\")\n",
    "print(f\"Der Grad der Ost-West-Symmetrie beträgt: {round(east_west_symmetry * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc2079",
   "metadata": {},
   "source": [
    "## Analyse der Schritte [Aufgaben 4, 5]\n",
    "### Simulation\n",
    "\n",
    "Für die Simulation wird die **Bibliothek Mesa** verwendet. Das hat den Vorteil, dass die Umgebung (mesa.Model) schrittweise durch Schritte verändert werden kann.\n",
    "In jeden **Simulationsschritt** (Step) führen die Agenten eine Aktion aus. Dadurch wird der Zustand der Umgebung verändert.\n",
    "\n",
    "Folgende Schritte sind für die Agenten möglich:\n",
    "\n",
    "- Aufnehmen eines Überlebenden (wenn sich der Agent an der Position des Überlebenden befindet und bereits keinen Überlebenden trägt)\n",
    "- Herablassen eines Überlebenden (wenn der Agent einen Überlebenden transportiert) \n",
    "- Bewegen zu einem Überlebenden \n",
    "- Bewegen zu einer SaveZone\n",
    "\n",
    "Beim Aufnehmen und Herablassen der Überlebenden werden nur noch nicht gerettete berücksichtigt.\n",
    "Beim Bewegen wird der **A-Star** Algorithmus zur Pfadfindung verwendet. Dieser beachtet die bisherigen Pfadkosten g(n) und die Heuristik-Funktion h(n). \n",
    "\n",
    "Als Heuristik wird die **Manhattan-Distanz** verwendet. Wegen der auf horizontale und vertikale Schritte begrenzten Bewegung im Labyrinth, bzw. Grid, liefert die Manhattan-Distanz eine realistischere und oftmals genauere Unterschätzung der tatsächlichen Pfadlänge (bei nicht-diagonalen Bewegungen), was ein wichtiges Kriterium für den A-Stern Algorithmus ist. \n",
    "\n",
    "Der euklidische Algorithmus kann die Pfadlänge zu sehr unterschätzen, da diagonale Bewegungen mit einbezogen werden könnten. Zudem würden mathematische Wurzeloperationen verwendet werden, weshalb der euklidische Algorithmus also rechenintensiver wäre als die Manhattan-Distanz.\n",
    "\n",
    "Die Umgebung wird nach jeder Aktion der Agenten aktualisiert, da sich bei mehr als einem Agenten die Roboter gegenseitig negativ beeinträchtigen könnten. Die Roboter agieren deshalb innerhalb eines Simulationsschrittes nacheinander, die Reihenfolge ist dabei nicht zufällig.\n",
    "\n",
    "Im Folgenden wird ein einzelner Simulationsschritt dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.step()\n",
    "print(\"Bewegte Felder des Agenten:\", environment.agents_by_type[RobotAgent][0].tiles_moved)\n",
    "environment.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225fc93",
   "metadata": {},
   "source": [
    "Der Agent 1 trägt zu Beginn keinen Überlebenden und befindet sich an einer der SaveZones.\n",
    "Da es Überlebende gibt, die noch nicht gerettet wurden, sucht der Agent 1 mittels des A-Stern Algorithmus den nächsten Überlebenden.\n",
    "\n",
    "Er findet den nächsten Überlebenden und bewegt sich zu diesem; dabei werden die benötigten Felder mitgezählt und in der Konsole ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d5d72",
   "metadata": {},
   "source": [
    "Der Agent 1 nimmt den Überlebenden an der selben Position auf. Nun soll der Überlebende an der nächsten SaveZone abgesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12057da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.step()\n",
    "print(\"Bewegte Felder des Agenten:\", environment.agents_by_type[RobotAgent][0].tiles_moved)\n",
    "environment.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926098ca",
   "metadata": {},
   "source": [
    "Der Agent 1 setzt den Überlebenden an der nächsten SaveZone ab. Von dort aus beginnt der Zyklus von vorne, bis alle Überlebenden gerettet wurden.\n",
    "\n",
    "Die Simulation wird nun automatisch bis zur Endbedingung (alle Überlebenden gerettet) fortgesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc89ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45929c",
   "metadata": {},
   "source": [
    "Die Simulation wurde nach dem 20. Schritt beendet, da alle Überlebenden gerettet wurden.\n",
    "\n",
    "Bei jedem Simulationsschritt werden Metriken zu Agenten und der Umgebung per mesa.data_collector gesammelt. Dies ist für den batch-run später wichtig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201801be",
   "metadata": {},
   "source": [
    "### Wahl der Save-Felder für die Überlebenden\n",
    "\n",
    "Nach dem Durchlaufen der Simulation bis zur Endbedingung wurden die Überlebenden zu ihren optimalen SaveZones gebracht.\n",
    "In der Visualisierung ist das zu erkennen:\n",
    "An den SaveZones (EXIT) sind Überlebende (SURV) abgesetzt. Die Position des Roboters (AGENT) ist die des zuletzt geretteten Überlebenden.\n",
    "\n",
    "Uns fiel in den Simulationen auf, dass isolierte SaveZones (*) oft eine Großzahl an Überlebenden beherbergen. Mit genug Simulationsdaten wäre diese Annahme interessant, zu überprüfen. Dafür müssten die Pfadlängen zwischen den SaveZones selbst und die am Ende beherbergten Überlebenden gesammelt und analysiert werden. \n",
    "\n",
    "_(*) Isolierte SaveZones sind SaveZones, die eine hohe Pfadlänge zu allen anderen SaveZones haben. Nach dieser Definition müsste es stets eine SaveZone geben, am isoliertesten von anderen SaveZone ist._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baeff96",
   "metadata": {},
   "source": [
    "### Optimale Startposition\n",
    "\n",
    "Für die optimale Startposition kann die Simulation für jede Startposition durchgeführt und anschließend ausgewertet werden.\n",
    "Voraussetzung dafür ist, dass nur ein Roboter für die Simulation verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use initial_environment as a deepcopy from the environment from before\n",
    "runs: List[Dict] = []\n",
    "\n",
    "for iteration in range(len(initial_environment.save_zones)):\n",
    "    tmp_environment: EnvironmentModel = deepcopy(initial_environment)\n",
    "    if len(tmp_environment._agents_by_type[RobotAgent]) > 1:\n",
    "        print(\"Zu viele Roboter für diese Aufgabe, bitte nur 1 Roboter verwenden.\")\n",
    "        break\n",
    "\n",
    "    # Override the start-savezone of the robot agent\n",
    "    start_save_zone: SaveZone = tmp_environment.save_zones[iteration]\n",
    "    tmp_environment._agents_by_type[RobotAgent][0].tile = start_save_zone.tile\n",
    "\n",
    "    # gather data\n",
    "    print(f\"\\nIteration: {iteration}. Start SaveZone: ({start_save_zone.tile.x},{start_save_zone.tile.y})\")\n",
    "    tmp_environment.run_model();\n",
    "    runs.append(\n",
    "        {\n",
    "            \"iteration\": iteration,\n",
    "            \"start_save_zone\": start_save_zone.tile,\n",
    "            \"steps\": tmp_environment.steps,\n",
    "            \"tiles_moved\": tmp_environment._agents_by_type[RobotAgent][0].tiles_moved,\n",
    "        }\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the iteration results:\n",
    "for run in runs:\n",
    "    print(f\"Start SaveZone: ({run['start_save_zone'].x},{run['start_save_zone'].y})\")\n",
    "    print(f\" - Benötigte Steps (Schritte): {run['steps']}\")\n",
    "    print(\n",
    "        f\" - Benötigte Felder (Tiles): {run['tiles_moved']}\"\n",
    "    )\n",
    "\n",
    "# best run:\n",
    "best_run: Dict = min(runs, key=lambda r: r[\"tiles_moved\"])\n",
    "print(f\"\\nBestes Ergebnis nach bewegten Feldern: {best_run['steps']} Schritte, {best_run['tiles_moved']} Felder (Tiles)\"\n",
    "    + f\" für Start-SaveZone ({best_run['start_save_zone'].x},{best_run['start_save_zone'].y})\")\n",
    "\n",
    "# Prozentuale Unterschied bester vs schlechtester tiles moved\n",
    "worst_run: Dict = max(runs, key=lambda r: r[\"tiles_moved\"])\n",
    "percentage_difference: float = (\n",
    "    (worst_run[\"tiles_moved\"] - best_run[\"tiles_moved\"]) / worst_run[\"tiles_moved\"]\n",
    ") * 100\n",
    "\n",
    "print(f\"Der schlechteste Run ist {round(percentage_difference, 2)}% \"+ \n",
    "    f\"({worst_run['tiles_moved'] - best_run['tiles_moved']} Felder) schlechter als der beste Run.\")\n",
    "\n",
    "# Standard deviation of tiles_moved\n",
    "std_dev: float = pd.Series([run[\"tiles_moved\"] for run in runs]).std()\n",
    "print(f\"Standardabweichung der bewegten Felder (Tiles): {round(std_dev, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b0842",
   "metadata": {},
   "source": [
    "Die Auswertung der optimalen Startposition zeigt folgende Ergebnisse:\n",
    "\n",
    "- Die benötigten Simulationsschritte sind bei allen Simulationen gleich. Es gibt bisher keine Begrenzung der gelaufenen Felder pro Simulationsschritt für den Agenten.\n",
    "- Selbst naheliegende Savezones können erheblichen Einfluss auf die gelaufenen Felder der Agenten haben, da eine leichte Wegänderung zu anderen gefundenen Pfaden und somit zu gänzlich anderen Durchläufen führen kann.\n",
    "- Die Standardabweichung der gelaufenen Felder ist oft nur ein paar Felder groß, bei Werten zwischen 50 und 200.\n",
    "- Die prozentuale Abweichung zwischen bestem und schlechtestem Run ist meist um die 10%.\n",
    "\n",
    "Daraus lässt sich schließen, dass die Wahl der Startposition für den Agenten einen großen Einfluss auf die benötigten Schritte der Simulation hat.\n",
    "In dem Szenario einer Katastophenrettung hat eine solche Wahl erheblichen Einfluss auf die benötigte Zeit, die letztendlich erheblich für das Überleben der Vermissten ist.\n",
    "\n",
    "Nicht untersucht wurde hierbei der Einfluss der Anzahl der Agenten auf die benötigte Zeit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229dc84e",
   "metadata": {},
   "source": [
    "## Eigene Erweiterung des Systems [Aufgabe 6]\n",
    "\n",
    "Als Erweiterung des Systems rund um die Simulation wählten wir eine erweiterte Auswertung des Systems.\n",
    "Dafür nutzten wir die von Mesa bereitgestellten **batch-run** Möglichkeiten, mit welchen die Simulationen sehr oft und effizient ausgeführt werden konnten.\n",
    "Anschließend wurden die generierten Daten mit **Pandas** in passende Formate umgewandelt und mit **Seaborn** (auf Matplotlib aufbauend) visualisiert.\n",
    "\n",
    "Hierbei verweisen wir auf die **Datei batch_run.ipynb**, in der die batch-run Simulationen und Analysen durchgeführt wurden.\n",
    "\n",
    "Damit die Simulationen auch für mehr als je einen Roboterhund als Agenten funktionieren, ermöglichten wir noch als **kleinen Zusatz** die Verwendung mehrerer Agenten parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cebf6b",
   "metadata": {},
   "source": [
    "## Anhang: Datensammlung\n",
    "\n",
    "Mit Mesa konnten wir die Daten pro Simulationsschritt sammeln. Hier folgt eine kurze Übersicht der gesammelten Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd002b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = environment.datacollector.get_model_vars_dataframe()\n",
    "agent_data = environment.datacollector.get_agent_vars_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model data:\")\n",
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agent data:\")\n",
    "agent_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_data.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
